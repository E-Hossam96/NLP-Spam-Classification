{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc25586a",
   "metadata": {},
   "source": [
    "# Models and Tokenizers Validity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a17b92",
   "metadata": {},
   "source": [
    "## Ensuring TensorFlow Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4554634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5e848f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "df = pd.read_csv('dataset/spam_email_raw_text.csv')\n",
    "df.drop(columns = ['FILE_NAME'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b1d08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the tokenizer\n",
    "import json\n",
    "fid1 = open('tf_tokenizer.json', 'r')\n",
    "tf_tokenizer = json.load(fid1)\n",
    "tf_tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(tf_tokenizer)\n",
    "fid1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98006eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "tf_model = tf.keras.models.load_model('tf_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5684f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the params\n",
    "fid2 = open('tf_params.json', 'r')\n",
    "tf_params = json.load(fid2)\n",
    "fid2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce271af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 1s 2ms/step - loss: 0.0073 - accuracy: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007317504845559597, 0.9981021285057068]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluating on the whole dataset\n",
    "df_sequences = tf_tokenizer.texts_to_sequences(df.MESSAGE)\n",
    "df_padded = tf.keras.preprocessing.sequence.pad_sequences(df_sequences, maxlen = tf_params['max_length'], \n",
    "                                                          padding = tf_params['padding_type'], \n",
    "                                                          truncating = tf_params['trunc_type'])\n",
    "tf_model.evaluate(df_padded, df.CATEGORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae7f2fd",
   "metadata": {},
   "source": [
    "## Ensuring NLTK Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "011cd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "import joblib\n",
    "nltk_model = joblib.load('nltk_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469a381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading parameters and processing functions\n",
    "from nltk_functions import text_to_tokens, text_to_count_vector\n",
    "fid = open('nltk_features.json', 'r')\n",
    "nltk_features = json.load(fid)\n",
    "fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b81096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import RegexpTokenizer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "# a function to process the whole dataframe of messages\n",
    "def df_to_X_y(df):\n",
    "    y = df.CATEGORY.to_numpy().astype(int)\n",
    "    messages = df.MESSAGE\n",
    "    count_vectors = []\n",
    "    for message in messages:\n",
    "        count_vector = text_to_count_vector(message, nltk_features, tokenizer, lemmatizer, stop_words, np)\n",
    "        count_vectors.append(count_vector)\n",
    "    X = np.array(count_vectors).astype(int)\n",
    "    return X, y\n",
    "\n",
    "X, y = df_to_X_y(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "480ed06b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9934437543133195"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk_model.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
